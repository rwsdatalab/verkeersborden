{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF9qm2TUQvwm"
      },
      "source": [
        "# Beter verkeersborden herkennen: Het DCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hQ4WYWxQvwp"
      },
      "source": [
        "Github: https://github.com/rwsdatalab/verkeersborden\n",
        "\n",
        "Deep Neural Networks (DNN's) zijn neurale netwerken met veel lagen. Deep Convolutional Neural Networks (DCNN's) zijn diepe netwerken ontworpen om convoluties (lokale transformatie functies) te leren. Deze laatste netwerken zijn op het moment de state of the art. \n",
        "\n",
        "Door convoluties te stapelen kan een netwerk als het filters leren voor complexe objecten (Bijvoorbeeld: Een stoel is een combinatie van stoelpoten en een zetel, een stoelpoot is een combinatie van rechte evenwijdige lijnen)\n",
        "\n",
        "## Tweede poging: Verkeersborden classificeren\n",
        "In deel I hebben we een netwerk gebouwd dat rond de 65% van de borden herkent. Het netwerk leerde snel, maar de prestaties liepen wat uiteen.\n",
        "\n",
        "Je zal zien dat met een paar kleine ingrepen we aardig beter gaan presteren."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow\n",
        "!pip install tensorflow==1.14.0"
      ],
      "metadata": {
        "id": "5nl_pRUhQ84c",
        "outputId": "07e84283-0a30-4e9e-d0ff-c6c44f8a5dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 45 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 69.5 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.48.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.5.3)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import os\n",
        "import random\n",
        "import skimage.transform\n",
        "import skimage.data\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "# Allow image embeding in notebook\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "Nqvm0ndARRez"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isfile('BelgiumTSC_Training.zip'):\n",
        "  !wget https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Training.zip\n",
        "  zf = ZipFile(\"BelgiumTSC_Training.zip\")\n",
        "  zf.extractall(\"../data/\")\n",
        "  zf.close()"
      ],
      "metadata": {
        "id": "Y46FpvPxQ4x5",
        "outputId": "5a21bea2-66c3-4a0a-bb85-4b874339a233",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-05 13:14:21--  https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Training.zip\n",
            "Resolving btsd.ethz.ch (btsd.ethz.ch)... 129.132.52.168, 2001:67c:10ec:36c2::168\n",
            "Connecting to btsd.ethz.ch (btsd.ethz.ch)|129.132.52.168|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 174298785 (166M) [application/zip]\n",
            "Saving to: ‘BelgiumTSC_Training.zip’\n",
            "\n",
            "BelgiumTSC_Training 100%[===================>] 166.22M  8.66MB/s    in 20s     \n",
            "\n",
            "2022-10-05 13:14:42 (8.35 MB/s) - ‘BelgiumTSC_Training.zip’ saved [174298785/174298785]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isfile('BelgiumTSC_Testing.zip'):\n",
        "  !wget https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Testing.zip\n",
        "  zf = ZipFile(\"BelgiumTSC_Testing.zip\")\n",
        "  zf.extractall(\"../data/\")\n",
        "  zf.close()"
      ],
      "metadata": {
        "id": "tUQ9UmBVQ40w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and testing datasets.\n",
        "ROOT_PATH = \"./\"\n",
        "train_data_dir = os.path.join(ROOT_PATH, \"../data/Training\")\n",
        "test_data_dir = os.path.join(ROOT_PATH, \"../data/Testing\")\n"
      ],
      "metadata": {
        "id": "uMiqNBExSbax"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SXgCC79PQvwq",
        "outputId": "98ef8dee-09db-4663-a99c-5af01ae94009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data is ingeladen in Python!\n"
          ]
        }
      ],
      "source": [
        "def load_data(data_dir):\n",
        "    \"\"\"Loads a data set and returns two lists:\n",
        "    \n",
        "    images: a list of Numpy arrays, each representing an image.\n",
        "    labels: a list of numbers that represent the images labels.\n",
        "    \"\"\"\n",
        "    # Get all subdirectories of data_dir. Each represents a label.\n",
        "    directories = [d for d in os.listdir(data_dir) \n",
        "                   if os.path.isdir(os.path.join(data_dir, d))]\n",
        "    # Loop through the label directories and collect the data in\n",
        "    # two lists, labels and images.\n",
        "    labels = []\n",
        "    images = []\n",
        "    for d in directories:\n",
        "        label_dir = os.path.join(data_dir, d)\n",
        "        file_names = [os.path.join(label_dir, f) \n",
        "                      for f in os.listdir(label_dir) if f.endswith(\".ppm\")]\n",
        "        # For each label, load it's images and add them to the images list.\n",
        "        # And add the label number (i.e. directory name) to the labels list.\n",
        "        for f in file_names:\n",
        "            images.append(cv2.imread(f))\n",
        "            labels.append(int(d))\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "images, labels = load_data(train_data_dir)\n",
        "\n",
        "print(\"Data is ingeladen in Python!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQFCMJqBQvwt"
      },
      "source": [
        "# Het DCNN\n",
        "Een DCNN is in feite een neuraal netwerk met meer dan 2 tussenlagen met minstens een convolutielaag. Maar daarnaast zijn er nog genoeg kleine aanpassingen die het model beter maken, zoals: Tussentijdse pooling en dropout layers. \n",
        "\n",
        "Eerst maken we een paar utilfuncties die ons straks gaan helpen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HiE9ViDnQvwu"
      },
      "outputs": [],
      "source": [
        "#To create this model, we're going to need to create a lot of weights and biases. \n",
        "#One should generally initialize weights with a small amount of noise for symmetry breaking, \n",
        "#and to prevent 0 gradients. Since we're using ReLU neurons, \n",
        "#it is also good practice to initialize them with a slightly positive initial bias to avoid \"dead neurons\". \n",
        "#Instead of doing this repeatedly while we build the model, let's create two handy functions to do it for us.\n",
        "\n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "#TensorFlow also gives us a lot of flexibility in convolution and pooling operations. \n",
        "#How do we handle the boundaries? What is our stride size? In this example, \n",
        "#we're always going to choose the vanilla version. \n",
        "#Our convolutions uses a stride of one and are zero padded so that the output is the same size as the input. \n",
        "#Our pooling is plain old max pooling over 2x2 blocks. To keep our code cleaner, \n",
        "#let's also abstract those operations into functions.\n",
        "\n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "def indices_to_one_hot(data, nb_classes):\n",
        "    \"\"\"Convert an iterable of indices to one-hot encoded labels.\"\"\"\n",
        "    targets = np.array(data).reshape(-1)\n",
        "    return np.eye(nb_classes)[targets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cmCAIVcIQvwv",
        "outputId": "5ebce1e5-ba52-4035-fdae-9d0372669848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  (4575, 62) \n",
            "images:  (4575,)\n"
          ]
        }
      ],
      "source": [
        "labels_a = indices_to_one_hot(labels,62)\n",
        "images_a = np.array(images)\n",
        "print(\"labels: \", labels_a.shape, \"\\nimages: \", images_a.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbsNNTBHQvww"
      },
      "source": [
        " Dan definieren we het deep net, zoals hier onder weergegeven:\n",
        "                \n",
        "Althans dit wordt gezien als een bescheiden diep netwerk..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fVAmUXJhQvww",
        "outputId": "3a7e49aa-0989-492f-fc12-c613bd166f18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-19-ee9a3a48dc4d>:30: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From <ipython-input-19-ee9a3a48dc4d>:36: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ]
        }
      ],
      "source": [
        "# Create a graph to hold the model.\n",
        "graph = tf.Graph()\n",
        "\n",
        "# Create model in the graph.\n",
        "with graph.as_default():\n",
        "    # Placeholders for inputs and labels.\n",
        "    images_ph = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
        "    labels_ph = tf.placeholder(tf.int32, [None,62])\n",
        "    images = tf.reshape(images_ph, [-1, 32, 32, 3])\n",
        "    \n",
        "    #two conv & pooling pairs\n",
        "    h_conv1 = tf.nn.relu(conv2d(images, weight_variable([3, 3, 3, 32])) + bias_variable([32]))\n",
        "    h_pool1 = max_pool_2x2(h_conv1)\n",
        "    h_conv2 = tf.nn.relu(conv2d(h_pool1, weight_variable([5, 5, 32, 64])) + bias_variable([64]))\n",
        "    h_pool2 = max_pool_2x2(h_conv2)\n",
        "    \n",
        "    #Now that the image size has been reduced to 8x8, we add a fully-connected layer with 1024 neurons \n",
        "    #to allow processing on the entire image. \n",
        "    #We reshape the tensor from the pooling layer into a batch of vectors, \n",
        "    #multiply by a weight matrix, add a bias, and apply a ReLU.\n",
        "    h_pool2_flat = tf.reshape(h_pool2, [-1, 8*8*64])\n",
        "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, weight_variable([8 * 8 * 64, 1024])) + bias_variable([1024]))\n",
        "\n",
        "    #To reduce overfitting, we will apply dropout before the readout layer. \n",
        "    #We create a placeholder for the probability that a neuron's output is kept during dropout. \n",
        "    #This allows us to turn dropout on during training, and turn it off during testing. \n",
        "    #TensorFlow's tf.nn.dropout op automatically handles scaling neuron outputs in addition to masking them, \n",
        "    #so dropout just works without any additional scaling.\n",
        "    keep_prob = tf.placeholder(tf.float32)\n",
        "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "\n",
        "    #Finally, we add a layer for softmax regression.\n",
        "    y_conv = tf.matmul(h_fc1_drop, weight_variable([1024, 62])) + bias_variable([62])    \n",
        "    \n",
        "    #variables for training and evaluation\n",
        "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels_ph, logits=y_conv))\n",
        "    train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cross_entropy)\n",
        "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(labels_ph, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))   \n",
        "    \n",
        "    init = tf.initialize_all_variables()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO-HC9uLQvwx"
      },
      "source": [
        "## Training\n",
        "We gaan het model nu 200 keer trainen. (We gebruiken de ADAM optimizer om de cross-entropy zo laag mogelijk te krijgen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a session to run the graph we created.\n",
        "session = tf.Session(graph=graph)\n",
        "\n",
        "# First step is always to initialize all variables. \n",
        "# We don't care about the return value, though. It's None.\n",
        "_ = session.run([init])\n",
        "\n",
        "print(\"sessie is aangemaakt!\")"
      ],
      "metadata": {
        "id": "GbjNrjbJTHxs",
        "outputId": "149ece00-1995-458a-feb4-13cbb61ea02d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sessie is aangemaakt!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "scrolled": false,
        "id": "FcNMRtX-Qvwy",
        "outputId": "010e5040-f8a2-4ea9-a78b-b559f50d3155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-1882d329f1f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     _, loss_value = session.run([train, cross_entropy],\n\u001b[0;32m----> 6\u001b[0;31m                                 feed_dict={images_ph: images_a, labels_ph: labels_a, keep_prob: 0.5})\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m           if (not is_tensor_handle_feed and\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ],
      "source": [
        "loss_values = []\n",
        "steps = []\n",
        "\n",
        "for i in range(201):\n",
        "    _, loss_value = session.run([train, cross_entropy],\n",
        "                                feed_dict={images_ph: images_a, labels_ph: labels_a, keep_prob: 0.5})\n",
        "    loss_values.append(loss_value)\n",
        "    steps.append(i)\n",
        "    if i % 10 == 0:\n",
        "        print(\"Loss: \", loss_value)\n",
        "\n",
        "print(\"het model is getraind!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYvWHqnKQvwy"
      },
      "source": [
        "## Evaluatie\n",
        "\n",
        "Eens kijken of we nu beter scoren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ERcd4dvQvwy",
        "outputId": "4d567e30-1339-4402-9b51-6a47cde4ffbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/stijn/anaconda2/envs/tensortut/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Truth:        38 Prediction: 39\n",
            "Truth:        38 Prediction: 39\n",
            "Truth:        38 Prediction: 39\n",
            "Truth:        38 Prediction: 39\n",
            "Truth:        38 Prediction: 40\n",
            "Truth:        38 Prediction: 40\n",
            "Truth:        38 Prediction: 35\n",
            "Truth:        23 Prediction: 28\n",
            "Truth:        23 Prediction: 28\n",
            "Truth:        23 Prediction: 28\n",
            "Truth:        23 Prediction: 28\n",
            "Truth:        23 Prediction: 32\n",
            "Truth:        23 Prediction: 28\n",
            "Truth:        14 Prediction: 16\n",
            "Truth:        14 Prediction: 7\n",
            "Truth:        17 Prediction: 7\n",
            "Truth:        17 Prediction: 7\n",
            "Truth:        16 Prediction: 14\n",
            "Truth:        16 Prediction: 18\n",
            "Truth:        16 Prediction: 14\n",
            "Truth:        16 Prediction: 18\n",
            "Truth:        16 Prediction: 14\n",
            "Truth:        16 Prediction: 18\n",
            "Truth:        16 Prediction: 14\n",
            "Truth:        16 Prediction: 18\n",
            "Truth:        56 Prediction: 57\n",
            "Truth:        39 Prediction: 38\n",
            "Truth:        3 Prediction: 13\n",
            "Truth:        3 Prediction: 13\n",
            "Truth:        3 Prediction: 13\n",
            "Truth:        58 Prediction: 35\n",
            "Truth:        58 Prediction: 35\n",
            "Truth:        58 Prediction: 35\n",
            "Truth:        58 Prediction: 35\n",
            "Truth:        46 Prediction: 45\n",
            "Truth:        46 Prediction: 47\n",
            "Truth:        46 Prediction: 45\n",
            "Truth:        46 Prediction: 45\n",
            "Truth:        42 Prediction: 40\n",
            "Truth:        42 Prediction: 40\n",
            "Truth:        42 Prediction: 40\n",
            "Truth:        5 Prediction: 3\n",
            "Truth:        5 Prediction: 3\n",
            "Truth:        6 Prediction: 7\n",
            "Truth:        6 Prediction: 18\n",
            "Truth:        6 Prediction: 7\n",
            "Truth:        6 Prediction: 7\n",
            "Truth:        6 Prediction: 4\n",
            "Truth:        6 Prediction: 7\n",
            "Truth:        45 Prediction: 46\n",
            "Truth:        45 Prediction: 46\n",
            "Truth:        45 Prediction: 50\n",
            "Truth:        45 Prediction: 47\n",
            "Truth:        45 Prediction: 47\n",
            "Truth:        45 Prediction: 46\n",
            "Truth:        45 Prediction: 46\n",
            "Truth:        45 Prediction: 46\n",
            "Truth:        45 Prediction: 47\n",
            "Truth:        57 Prediction: 56\n",
            "Truth:        57 Prediction: 53\n",
            "Truth:        57 Prediction: 56\n",
            "Truth:        57 Prediction: 56\n",
            "Truth:        57 Prediction: 56\n",
            "Truth:        57 Prediction: 56\n",
            "Truth:        2 Prediction: 13\n",
            "Truth:        2 Prediction: 14\n",
            "Truth:        2 Prediction: 13\n",
            "Truth:        2 Prediction: 18\n",
            "Truth:        2 Prediction: 13\n",
            "Truth:        2 Prediction: 13\n",
            "Truth:        7 Prediction: 18\n",
            "Truth:        7 Prediction: 18\n",
            "Truth:        7 Prediction: 18\n",
            "Truth:        7 Prediction: 18\n",
            "Truth:        7 Prediction: 18\n",
            "Truth:        0 Prediction: 1\n",
            "Truth:        0 Prediction: 1\n",
            "Truth:        0 Prediction: 1\n",
            "Truth:        0 Prediction: 1\n",
            "Truth:        13 Prediction: 32\n",
            "Truth:        13 Prediction: 56\n",
            "Truth:        13 Prediction: 32\n",
            "Truth:        20 Prediction: 24\n",
            "Truth:        18 Prediction: 17\n",
            "Truth:        18 Prediction: 7\n",
            "Truth:        18 Prediction: 8\n",
            "Truth:        18 Prediction: 17\n",
            "Truth:        18 Prediction: 17\n",
            "Truth:        18 Prediction: 10\n",
            "Truth:        18 Prediction: 10\n",
            "Truth:        18 Prediction: 8\n",
            "Truth:        18 Prediction: 10\n",
            "Truth:        43 Prediction: 42\n",
            "Truth:        43 Prediction: 42\n",
            "Truth:        43 Prediction: 42\n",
            "Truth:        43 Prediction: 42\n",
            "Truth:        43 Prediction: 42\n",
            "Truth:        43 Prediction: 42\n",
            "Truth:        53 Prediction: 39\n",
            "Truth:        21 Prediction: 28\n",
            "Truth:        21 Prediction: 22\n",
            "Truth:        21 Prediction: 22\n",
            "Truth:        24 Prediction: 25\n",
            "Truth:        24 Prediction: 25\n",
            "Truth:        24 Prediction: 25\n",
            "Truth:        4 Prediction: 8\n",
            "Truth:        4 Prediction: 18\n",
            "Truth:        4 Prediction: 7\n",
            "Truth:        4 Prediction: 18\n",
            "Truth:        4 Prediction: 18\n",
            "Truth:        4 Prediction: 18\n",
            "Truth:        55 Prediction: 56\n",
            "Truth:        8 Prediction: 13\n",
            "Truth:        8 Prediction: 18\n",
            "Truth:        8 Prediction: 13\n",
            "Truth:        8 Prediction: 4\n",
            "Truth:        8 Prediction: 3\n",
            "Truth:        60 Prediction: 61\n",
            "Truth:        60 Prediction: 21\n",
            "Truth:        60 Prediction: 61\n",
            "Truth:        60 Prediction: 61\n",
            "Truth:        60 Prediction: 21\n",
            "Truth:        49 Prediction: 47\n",
            "Truth:        49 Prediction: 47\n",
            "Truth:        59 Prediction: 56\n",
            "Truth:        27 Prediction: 32\n",
            "Truth:        27 Prediction: 32\n",
            "Truth:        27 Prediction: 24\n",
            "Truth:        27 Prediction: 32\n",
            "Truth:        12 Prediction: 7\n",
            "Truth:        12 Prediction: 18\n",
            "Truth:        12 Prediction: 18\n",
            "Truth:        10 Prediction: 22\n",
            "Truth:        10 Prediction: 7\n",
            "Truth:        10 Prediction: 14\n",
            "Truth:        10 Prediction: 14\n",
            "Truth:        10 Prediction: 14\n",
            "Truth:        10 Prediction: 17\n",
            "Truth:        32 Prediction: 14\n",
            "Truth:        32 Prediction: 19\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 34\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 28\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 56\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 54\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n",
            "Truth:        35 Prediction: 38\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHxxJREFUeJztnXmMXNeV3r/zXlc3e1/Y3EWJpESZ\n1EpSrcWSItvyEtkziWzA49h/GApgjAbBeBADEwSCA8QOkD88QWzDARIndCRYE2i8ZGzHQqDYY2vk\noaXxUKIoiRRFiaIo7s2dzWZv1V31Tv7o0oCi7ne7yCarKd/vBzS6+5533zv16p16Vferc465O4QQ\n6ZHNtQNCiLlBwS9Eoij4hUgUBb8QiaLgFyJRFPxCJIqCX4hEUfALkSgKfiESpWk2k83sAQDfAZAD\n+J/u/o3Y9q1trd7Z3Rm0xb5oyL6FmGXG54Db4AU1WWSeZ+S1slrlcyz2wPixIt4DscfNzpXF9sht\nRcHPFXDh3w7N8vyC5wBAU2ReETn/zHuLnPuq8/1FiVzEFjn/XoTneeT8NjWVguPDQ2cwPjYevXz+\ncR/1bBTCzHIA/xXAxwEcBPCCmT3p7q+xOZ3dnfjsv/xc0DZViTyB1ang+LzWVjqnGnlTUymXqa0l\n8iRV29rD40NDdE7RzJ9Ar4afQADII0983sznTRUTwfF5TfPonAJ8f5MTY9RWRYXajDyf7b293I+C\nXwMLe7qp7ezIKLWVK+Hwz5y/mIxO8f2hyl8Mq5OT1Nbc0kxtlbHw9VgBPx/9CxcFx5/4H0/QOecz\nm7f9dwDY7e573H0SwA8BPDiL/QkhGshsgn8ZgAPn/H+wNiaEeB8wm+APvT9+z3tVM3vYzLaY2Zbx\nsfFZHE4IcSmZTfAfBLD8nP+vAnD4/I3cfaO7D7j7QGsb/4wuhGgsswn+FwCsNrOVZtYM4PMAnrw0\nbgkhLjcXvdrv7hUz+zKAX2Ja6nvM3XfE5mRZjvaOsNR35tRpOq+VrJROnD1L55Rz/tC65rVRWxGR\ngKbK4ZX0mLLQlPOV9NYW7qNxF9GchVUHALCJ8Gr6yTJfib5+RR+1HTl8lNqKjK98Z+WwSjBOVt8B\noH8hVwLKw1x1mAJfuS/l4ZX0M2fCzyUAZM0R6bbMVZj2jh5qK49xRWicyME+wVWpwYOHguNTU/x5\nPp9Z6fzu/hSAp2azDyHE3KBv+AmRKAp+IRJFwS9Eoij4hUgUBb8QiTKr1f4LpSgKjI+HJZYskv02\nrzUsbWXN/EtDk6e4tNISyXma7OAJGL3lcCLLWDPX5T617FZq23TrndQ2+BaXMY9s301t+Yn9wfHx\nrsV0zs7X+LmvTIWlWQDoHT9BbatWhr/p3Tx2IDgOACeOc7nXRkeorbk7kvQzHJYWW1r5pe/hPDIA\nQCWSqFUe589ZdZLLh60d4etnfILLkd1kTs4yTwPozi9Eoij4hUgUBb8QiaLgFyJRFPxCJEpDV/sB\nR5WU5CoiZatGx8JJHW2RBJ2Oni5qO332DLVVhk5S28Q164Pjh0c76JxH/tv3qa2956+orXMpTxJp\nbeeP20iSix9/nc45c/QItZ06NExtJ0rcxyNHwqv9ec4VmlULqQlXLeXPZ3mU+1hqbgmOT4zxlfRS\nC0/GGpvgNSlaqvxe6nmkht9oeJ+lUth3ABgdDcdEvObiu9GdX4hEUfALkSgKfiESRcEvRKIo+IVI\nFAW/EInSYKkPaCKKR4kk7wBAtRKuSzY8GUmkGOW1zOaROoIAsHuE+/HW4+GKZbfetTw4DgALN/BW\nBvu2v6fY8T9y4IU91OYWedpI6ycUPFulpYXfAxYs4nLe1Wv5Yzu4L5z0c/gtLiuODK+ktt08lwnr\n10TqJHaRjj3GH3M5klDTRaRDAKhGZLbJKd7dqLmJ1KisRjoAEfejXdnOQ3d+IRJFwS9Eoij4hUgU\nBb8QiaLgFyJRFPxCJMqspD4z2wvgLIAqgIq7D8S2dwBTRViLMERaJJEWWm0Rya6c8VZHL+7kEqEf\n51LULfeuCY7/7tntdE4WqQdXdZ7JaBE5zyP1Dpktb+a1CcemuEQ1epBnQB45/Aq1IQvLVAO3r6NT\n3hg8SG0njvNDPb9zAbWtWRqW2Lr6I22tci73njnDr50iUvyvKZ9HbRULX/vdvdwPjIWPFZMw3+NT\n3VtyPuLuvJKjEOKKRG/7hUiU2Qa/A/gbM3vRzB6+FA4JIRrDbN/23+Puh81sIYBfmdnr7r7p3A1q\nLwoPA0BHF694I4RoLLO687v74drvYwB+BuCOwDYb3X3A3QfmtfESTkKIxnLRwW9m7WbW+c7fAD4B\n4NVL5ZgQ4vIym7f9iwD8zKbTiJoA/JW7/yI6w236J0Be4lLUxNmwvJKf5ZLXzkjhyWyQt4zCNVdT\n0/N/F35ty5xLZVMeLqgJAHksBSuyT48UO2VpXdUql1JjqWAZuK1KnksAKIpw9tvzm3fSOV0Refb2\n+2+jtn/429eo7ZVyuCrooqNc6lt1A78ntkRaxCHj4dTSxPc5UQk/n+WJSGZqpCBovVx08Lv7HgC8\nEZ0Q4opGUp8QiaLgFyJRFPxCJIqCX4hEUfALkSgN79VXqYSzkZqcu9LWFs6IGung3xh8+8kd1HbT\nPWupbesz/KsKy7rDcuTKf3ITnfPS1v3UNnaUy5GRJEcgIvUZyxS8gGyvc8kix4r1V2RCFKsvCgBD\n4D0IX/rFVmob+BA//1u3hguhHvX5dI69xjP3Vt/cS23lMS7NjUUKeM6fHy6SGusZ2NoallKznEvL\n79m27i2FEL9XKPiFSBQFvxCJouAXIlEU/EIkSkNX+4uiwOTEWNDW2s7bIE15eKV0+4uH6Jzb1/ME\nned+9zq1dZT4MvuNd4VVgnKkrdLtA9yPbW/weoHHX+dF65oyntTBFtNjraSyjN8DPHp/4Ptk9xWL\nKQSRlmLlnK98v/QcTxbasH5VcPyF14/SOcczXjuv/+AotXUu5tdwaxtXMjwjiT3lcKwAQHc3We2/\ngNu57vxCJIqCX4hEUfALkSgKfiESRcEvRKIo+IVIlIZKfWZAVgonHlSnuMxzthqWtoZ2vEHntA+s\npramiQlqu/cj66ltoiXsR7NzGapa4Qkdt65aQm27WvhTc3Abb2tlHn49zyLyYKRMH6qRTJxoayhW\ngzDSaqyI1BIsGU9YqUQkx+1bdwfHB+79AJ2zdTNPxtpR7aO2u9q4H/mCiCxqYdmup7eLTymRWoIX\nkMClO78QiaLgFyJRFPxCJIqCX4hEUfALkSgKfiESZUapz8weA/CHAI65+021sT4APwKwAsBeAJ9z\n99N17AvNTWFZrKhwKWR0MiwB9XfxFl979vCMueaI7DXVxLP6jKiR3hLJiou16yLZigBw3fJ+auvs\n4BLQq/8QzlgsFdwPN+5HrJVXtGEUM0YmFQU39kVktJNNvB5f5eyp4Phrz/IWX+s/dAu1bXsuXBMQ\nAHa8ybMBb+vjtf9KreEw7OrkrcGu6gnLgy0X0Marnjv/9wE8cN7YIwCedvfVAJ6u/S+EeB8xY/C7\n+yYA5798Pgjg8drfjwP49CX2SwhxmbnYz/yL3H0QAGq/w61QhRBXLJd9wc/MHjazLWa2ZWKMf61W\nCNFYLjb4j5rZEgCo/T7GNnT3je4+4O4D80jzDSFE47nY4H8SwEO1vx8C8PNL444QolHUI/X9AMCH\nAfSb2UEAXwPwDQA/NrMvAdgP4I/qOViWZWjtCBcyHBvlRTBHKuXgeO8iLvHsfZMrj0VE9tr065eo\n7a77bg2Ol3J+GmNZcZVYol3G5bdFnXyfJdK6avszvH2ZsxZfAEhtSQBRFZDm2XlEzusCvwbWRlqi\nbXmbtz0bOxu+v5WbeLHNw3/Ps0Vbli+ituPHeZsvDI5TU/e6BcHxThIrAHDTH9wXHG/9zg+4D+cx\nY/C7+xeI6aN1H0UIccWhb/gJkSgKfiESRcEvRKIo+IVIFAW/EInS0AKe7kBlMqwdTXlYzgOAqXJY\nOGpr51lUPsV73RUR/apScAlo86ZXg+MbbruWzmldyH3MM376i2qk4GMTl8sWEInwlo/fTOe8/Mw2\nassi2ZbxvL6wrang3/K88xMbqM0jV2r/gh5q27/rcHDcIpLjCefFZNfN55l2L+4foratb/Lr8V/c\nf31wfM3alXTOoQNheXNyMvZ8vRvd+YVIFAW/EImi4BciURT8QiSKgl+IRFHwC5EoDZX6AIcTGaWz\nmWcw5U0jZHe82GbUi2j/OT5vgpyuF59/m875wPW8t9uCNVdRW0SJQhZ5zXaSaregxOWrez/JJbZN\nv95KbU2jkWKnebh2w913r6Bzqs38cZE2iQCABZ28kOs+IjlmBZfEKuBZn2+9vJPaeq/l0tzQYZ7x\nt7ISvr7HO7mE2UJ6IWaIpGG+Z1shRJIo+IVIFAW/EImi4BciURT8QiRKY1f7LUPeEl4Fbivx1f72\nCbIye4wnicTqy2XOjdXIamlGat1NRl5Cd+w6SW2rRvkK/PJ1V1MbWegFAFhOVqot3CYNAFoLnlT1\nkY/dSG3P/eYtart5Yfj5zPt4BeemyJM2FVmdb2N91ABUSfJUFkkky5w/oacKfp3euYgnhb2yhyf2\nPPWzLcHxBzfcTedMERc9cp7OR3d+IRJFwS9Eoij4hUgUBb8QiaLgFyJRFPxCJEo97boeA/CHAI65\n+021sa8D+GMA7+gXX3X3p2bcFwAjiRbHT9Fen+gg0tyh0yf4sVoiyS/lSEJQRAYsSBOqPFLLrhp5\ned07eIbaRkd2Uduau1dTm2dE6im4I7H0qHyKtw27775VfF4WPp5HahN6RMPMIufYCy715a1E+hyL\nJUfF5F7ux8guLudNlfg+d54I+/LPq/xxzevuDo5bXv/9vJ4tvw/ggcD4t919Xe1nxsAXQlxZzBj8\n7r4JwKkG+CKEaCCz+cz/ZTPbZmaPmVnvJfNICNEQLjb4vwvgWgDrAAwC+Cbb0MweNrMtZrZlfGzs\nIg8nhLjUXFTwu/tRd6/69ArN9wDcEdl2o7sPuPtAaxv/XrQQorFcVPCb2ZJz/v0MgHArGyHEFUs9\nUt8PAHwYQL+ZHQTwNQAfNrN1ABzAXgB/Us/BvChQGQ9n4nV28DZIfipc4+zkSV4XrWUJr39W3kdq\nAgJAlQtfWSxVkBCbUcl4rbhDw/wj0sSvX6G22z5+e3C8DL6/poxn/GUl7mNR4TJglWTG5ZH7DZNS\nAWCqwp+XPCLNtc4Pt0ubINchAMTK4BURYXTwOJdu26+9htpOvX0oON7bw30s5YuC45nVfz+fMfjd\n/QuB4UfrPoIQ4opE3/ATIlEU/EIkioJfiERR8AuRKAp+IRKloQU8szxDW1dYeonJPH09YdnOVi6j\nc67u4cUU33ibSzIZyUYDgIJknXlU0IvoRlUulZlzie1kldv+/qnfBcc/+PH1/FiRXlhe5f7nGW+T\nBVJIsihiLb74uW9q4o8Zzs9jz8Jw9tuRA7ywqkUy9yzj/o9EztU1/fwLbof2hR93yzj3Y7IjfO5Z\nu7YQuvMLkSgKfiESRcEvRKIo+IVIFAW/EImi4BciURoq9RVFgYnxcHbZ2AjPYJrf3x8cX3v9Yjpn\n6JUj3JGcSzJFJHvM6WtlpD9aROnj+wMQLSLJpa1xC/fC2/Q0z7r+6CdupbYyKwgKIM8vXOKMqGh0\nDgAY6ZMIAO78Ml7cF5Z8ByPFQvNItmUeyZorZfzBtTdHpEpSgLQlIn3+5rfbguMjI+P8OOehO78Q\niaLgFyJRFPxCJIqCX4hEUfALkSgNXe13d5THy0GbRVZKzw6F23K1G68999Lxw9S27Oarqe3Qy4PU\nBuftkxjxNIvI6vZFzeKr6WuuXkjnTEYWomN1C2NJOh5ZnY9M4n7k3MlKpJZgRyl8jVjkvpdZ5HEV\n3MdIXg8Km6S2ElEXJjvCKhcAjEyGr9PYc3I+uvMLkSgKfiESRcEvRKIo+IVIFAW/EImi4BciUepp\n17UcwF8CWIzpDJaN7v4dM+sD8CMAKzDdsutz7n46tq88b0JvX1/Qdub0EJ9I6qbl87j71913A7VN\n7eAy4P4WnvDRTGqqFZEknFhNtViySpTItPkdZHwtl41YvT0A8IgEG3c/PC9Wi88jrdKKiMQWK1vX\nVAlLbHkbrz+YTfIks0j5RNgUP4/VaqQlGqnl+P/+NlyPEQDaz4Ylc7av4LZ1bFMB8OfuvhbAXQD+\n1MxuAPAIgKfdfTWAp2v/CyHeJ8wY/O4+6O5ba3+fBbATwDIADwJ4vLbZ4wA+fbmcFEJcei7oM7+Z\nrQCwHsBmAIvcfRCYfoEAwL9CJoS44qg7+M2sA8BPAHzF3YcvYN7DZrbFzLaMj/I20UKIxlJX8JtZ\nCdOB/4S7/7Q2fNTMltTsSwAcC811943uPuDuA63tvHGBEKKxzBj8ZmYAHgWw092/dY7pSQAP1f5+\nCMDPL717QojLRT1ZffcA+CKA7Wb2cm3sqwC+AeDHZvYlAPsB/NFMOyqKKsbHR8OORLK28uZwXbpS\nJMluaTOXhv6OyD8AsO6OVdT26m/3hA0Fl1eiGXgRW0y+aonUn1t3983EwqUmZGHZCACKSH6hF9yW\nZeFHV6nwY+WRLM2LLJOIJlIHr6WXvwudOsKlPjd+0XXl3P/hM+HrHgDml8IPbng/92P19b3B8TzW\n1uw8Zgx+d38WPMP0o3UfSQhxRaFv+AmRKAp+IRJFwS9Eoij4hUgUBb8QidLQAp6AUemoa2EPnTVx\nZiQ4XnSEWzEBgB3nMtSH7+UZf8/9nxepbdnNVwXHD27fR+cgUk/RI/pVCVyOvPf+26itYkRKIy2h\nao5EbNzHSMIfCioD8kuuAi6ZWkT7zCNZlSCtzToWdtMpp4+corYMrdTWv4hfj3v2nqS2O5eGMwwX\ncBfRsXhBcDwnBUtD6M4vRKIo+IVIFAW/EImi4BciURT8QiSKgl+IRGlsr77CURkLS07NfVwmGa6e\nCY5PHuPyybwurpOMT/KiInf+szupbesvwgUV+1fzIkZHdx2htsz5a+91166mtqFyJDOOPLTmpkhh\n0mZ+GeQlniVWjWQzGnlosWxFM+6HRfTILNJDkfmxaH4nncOFPqC5zCXY/rU8I/Tt3+6gtls+dHdw\nfMGKsLQMAD2lruB4bvVn9enOL0SiKPiFSBQFvxCJouAXIlEU/EIkSkNX+/OmHD3zw7XHzgzzlftW\nUsOvNVKH7ciRyCo7WwIG0NbFl6Ov+mC4Pt7R516lc1atWUlt+17fS2273tpPbdjDV3QLJ5lEkXZX\nTZHac9GcH5I0A/C6bx7xI3YriiUR5ZEEqZzUEpyKLIpn4K28rl7BE3u2vh4sYA0A2LCsndo6usOt\n1PJIteujQ2EFbOoSt+sSQvweouAXIlEU/EIkioJfiERR8AuRKAp+IRJlRqnPzJYD+EsAizHdNGmj\nu3/HzL4O4I8BHK9t+lV3f2qm/RVFWJbJMi6vHDp8ODjeNo8nA/V0c0mm0sLn5RO86N7SPNw+qfuj\n6+ic3/4ynAwEAHd88BZqe3bzTmprjbTJcibO5XxONVZoMCL2RRRTFETSs1JEs4uogJGHjCKSIDVF\nbFnkIXe1cemw6aprqK331dep7bbP3kFtPcvDiWHjkQSu5jx8fVukvdr51KPzVwD8ubtvNbNOAC+a\n2a9qtm+7+3+u+2hCiCuGenr1DQIYrP191sx2Alh2uR0TQlxeLugzv5mtALAewOba0JfNbJuZPWZm\n4a/uCSGuSOoOfjPrAPATAF9x92EA3wVwLYB1mH5n8E0y72Ez22JmW8ZGeRENIURjqSv4zayE6cB/\nwt1/CgDuftTdq+5eAPgegOCKhrtvdPcBdx9oi3xXWQjRWGYMfptulfIogJ3u/q1zxpecs9lnAPDs\nFiHEFUc9q/33APgigO1m9nJt7KsAvmBm6zAt0OwF8Ccz7ciLKsqjo0FbNeevQ12kHl+pLZLVd5Bn\n9S1cyB/28RMnqK21NTyvtcr398DHNlDbL5/ZTW0Da/ma6t4xXkfu9JvhzLJSztPYPCb1ZZH7Q0Sa\nsyx8vKJ6ce2/Yu26YrBWXovmhzNFAaD32uXUdvCF7dT2wCd5G7imbl4z8PRwuB2dR+oFTmVhGbCo\nxmTb83yaaQN3fxbhDM0ZNX0hxJWLvuEnRKIo+IVIFAW/EImi4BciURT8QiRKQwt4Wp6h1B2W51oi\nrhwlWX2lEi88uXRhuCgiAAyPD1NbSwcvtNhO2lpNFFxGOzPEmz/dfeciajs9yh+b7dlHbRtuuz44\nfjIiAQ2+wfdXnYy0woq0hnKSvZlHJDszLgPGJKyuSCHXG28Ktz07sH+Qzjn22hvU9pFP38b96OKZ\nqQuW8tZbY5Mkey/Weqsg5+MCFFHd+YVIFAW/EImi4BciURT8QiSKgl+IRFHwC5EoDZX6JicmcXD3\n3qCtva2DzuvqCBcrHB0dp3NaWrhUVsp5Ac/mLFykEwCGyPGKSNHPPHKGy6O8QGN/B5+48N4bqW1w\nOOzjyVfepnOWdPZQ24Jl4eKSAOCd/ByjEpYIY5l7TZGKoBV+qnDgwFFqO7T5heD4n/2Xf0vn7NjB\nsy3t8AFqW7HmVmobPXuW2lo6wlJlNSJl+1RYFrVYVdXz0J1fiERR8AuRKAp+IRJFwS9Eoij4hUgU\nBb8QidLgrD5DU3tYZmuJFIocJ8lezSU+pzwSLooIAFORYqFNUzyLrTpZCY73L55P54wM8QzCfDGX\nN7NRLjl2d/B5HV3hwpTXLOmic3r6eAbk0BiXMU+fjJzjUVLAs+Dy1dbfvUhtefU0tRUFf842dIYz\n7QaHeQ+JA5teorYbP/gBajs1coba2ufxAp4TI+Giti3tvN/kpUB3fiESRcEvRKIo+IVIFAW/EImi\n4BciUWZc7TezeQA2AWipbf/X7v41M1sJ4IcA+gBsBfBFd+f9hQAYDM2kjdOCXr4a/eb+cOJG91K+\nyn747f3UtrS3j9pOTfBV4AUd4bZhZ0gLMgBobY4kZ0RW9GOvyx5RRsoT4adgQR9P3mlu4fvrI0lV\nANC0mNesu/NDdwfHR8u8Tt+f7efJR7YvXMcRADLjfmwm53jZm2/SOdfdGa77BwDL16yitvEpnrXk\nkeuquTWs0FSmwuoSAMzrCicDWV5/Eb967vxlAPe7+62Ybsf9gJndBeAvAHzb3VcDOA3gS3UfVQgx\n58wY/D7NO4JuqfbjAO4H8Ne18ccBfPqyeCiEuCzU9ZnfzPJah95jAH4F4C0AQ+7+zvuSgwB4W1kh\nxBVHXcHv7lV3XwfgKgB3AFgb2iw018weNrMtZrZlYjz2GVcI0UguaLXf3YcA/AbAXQB6zOydBcOr\nAARXZNx9o7sPuPvAPLKwIYRoPDMGv5ktMLOe2t+tAD4GYCeAZwB8trbZQwB+frmcFEJceupJ7FkC\n4HGb7s2UAfixu/9fM3sNwA/N7D8CeAnAozPtKEOGjix8999/nCdutLWF57SW+DuJ7m6eSFG0cvmq\ndZKrlePl8MeWUhs/1vBxXl9uWaSFUzWS1DFy7Di1dfWEJdNyNfipDADQ180l02KMF89bdxevJXiG\nJEGVTw7ROdd98l5q2/u916ltyvljKxCWWkdfe5XOufUP/im1DVf5/fLgrl3UNnDLGmrL2HPdwiXM\n0TPhpCqLtEM7nxmD3923AVgfGN+D6c//Qoj3IfqGnxCJouAXIlEU/EIkioJfiERR8AuRKOYRmeSS\nH8zsOIB9tX/7AZxo2ME58uPdyI93837z4xp3X1DPDhsa/O86sNkWdx+Yk4PLD/khP/S2X4hUUfAL\nkShzGfwb5/DY5yI/3o38eDe/t37M2Wd+IcTcorf9QiTKnAS/mT1gZm+Y2W4ze2QufKj5sdfMtpvZ\ny2a2pYHHfczMjpnZq+eM9ZnZr8zszdrv3jny4+tmdqh2Tl42s081wI/lZvaMme00sx1m9q9r4w09\nJxE/GnpOzGyemT1vZq/U/PgPtfGVZra5dj5+ZBapXFoP7t7QHwA5psuArQLQDOAVADc02o+aL3sB\n9M/Bce8DsAHAq+eM/ScAj9T+fgTAX8yRH18H8G8afD6WANhQ+7sTwC4ANzT6nET8aOg5AWAAOmp/\nlwBsxnQBnR8D+Hxt/L8D+FezOc5c3PnvALDb3ff4dKnvHwJ4cA78mDPcfROAU+cNP4jpQqhAgwqi\nEj8ajrsPuvvW2t9nMV0sZhkafE4ifjQUn+ayF82di+BfBuDAOf/PZfFPB/A3ZvaimT08Rz68wyJ3\nHwSmL0IAC+fQly+b2bbax4LL/vHjXMxsBabrR2zGHJ6T8/wAGnxOGlE0dy6CP1RqZK4kh3vcfQOA\nTwL4UzO7b478uJL4LoBrMd2jYRDANxt1YDPrAPATAF9xd97bvPF+NPyc+CyK5tbLXAT/QQDLz/mf\nFv+83Lj74drvYwB+hrmtTHTUzJYAQO33sblwwt2P1i68AsD30KBzYmYlTAfcE+7+09pww89JyI+5\nOie1Y19w0dx6mYvgfwHA6trKZTOAzwN4stFOmFm7mXW+8zeATwDghd0uP09iuhAqMIcFUd8Jthqf\nQQPOiU0XnnsUwE53/9Y5poaeE+ZHo89Jw4rmNmoF87zVzE9heiX1LQD/bo58WIVppeEVADsa6QeA\nH2D67eMUpt8JfQnAfABPA3iz9rtvjvz4XwC2A9iG6eBb0gA/7sX0W9htAF6u/Xyq0eck4kdDzwmA\nWzBdFHcbpl9o/v051+zzAHYD+N8AWmZzHH3DT4hE0Tf8hEgUBb8QiaLgFyJRFPxCJIqCX4hEUfAL\nkSgKfiESRcEvRKL8fxxz+L8xlS8RAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f71eed1b5c0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the test dataset.\n",
        "test_images, test_labels = load_data(test_data_dir)\n",
        "#test_labels_1h =  indices_to_one_hot(test_labels,62)\n",
        "\n",
        "predicted = session.run([tf.argmax(y_conv,1)], \n",
        "                        feed_dict={images_ph: test_images, keep_prob: 1})[0]\n",
        "\n",
        "for i in range(len(predicted)):\n",
        "    if predicted[i] != test_labels[i]:\n",
        "        plt.imshow(test_images[i])\n",
        "        print(\"Truth:        {0} Prediction: {1}\".format(test_labels[i], predicted[i]))\n",
        "    #truth = sample_labels[i]\n",
        "    #prediction = predicted[i]\n",
        "    #plt.subplot(5, 2,1+i)\n",
        "    #plt.axis('off')\n",
        "    #color='green' if truth == prediction else 'red'\n",
        "    #plt.text(40, 10, \"Truth:        {0}\\nPrediction: {1}\".format(truth, prediction), \n",
        "    #         fontsize=12, color=color)\n",
        "    #plt.imshow(sample_images[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0AfpmpgQvwz",
        "outputId": "4515a729-ae13-4e02-a173-356891522060"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/stijn/anaconda2/envs/tensortut/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.934127\n"
          ]
        }
      ],
      "source": [
        "# Load the test dataset.\n",
        "test_images, test_labels = load_data(test_data_dir)\n",
        "test_labels =  indices_to_one_hot(test_labels,62)\n",
        "\n",
        "# Run predictions against the full test set.\n",
        "acc = session.run([accuracy], feed_dict={images_ph: test_images, labels_ph: test_labels, keep_prob: 1.0})[0]\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AGYO3QVVQvwz"
      },
      "outputs": [],
      "source": [
        "# Close the session. This will destroy the trained model.\n",
        "session.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}