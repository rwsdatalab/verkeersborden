{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSe48RB-8GBO"
      },
      "source": [
        "# Verkeersborden herkennen met Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cxWZbLb8GBS"
      },
      "source": [
        "Github: https://github.com/rwsdatalab/verkeersborden\n",
        "\n",
        "Dit notebook is het eerste deel van een tutorial waarin we met deep learning verkeersborden gaan herkennen. Het doel van dit deel is om kort uit te leggen wat deep learning is, en vervolgens een eerste model te bouwen en te evalueren. Dit project is geinspireerd door deze [pagina](https://medium.com/@waleedka/traffic-sign-recognition-with-tensorflow-629dffc391a6)\n",
        "\n",
        "## Neurale Netwerken\n",
        "Neurale Netwerken (NN's) zijn computer programma's die patronen kunnen herkennen. Ze zijn geinspireerd op hoe hersenen zijn ontworpen: Neuronen (Nodes) die aan elkaar verbonden zijn en leren hoe ze moeten reageren op inkomende signalen. Die nodes zijn georganiseerd in lagen.\n",
        "\n",
        "NN's bestaan al jaren, maar zijn tegenwoordig weer populair omdat de techniek toelaat dat we veel lagen gebruiken: Deep Learning.\n",
        "\n",
        "Dit notebook leert je een vrij ondiep netwerk te bouwen met behulp van Tensorflow. Meer in deel 2.\n",
        "\n",
        "## Eerste poging: Verkeersborden classificeren\n",
        "Gegeven een afbeelding van een verkeersbord zullen we moeten bepalen wat voor verkeersbord we zien (bijvoorbeeld: Een voorrangsbord of een stopteken).\n",
        "\n",
        "Voor de project gebruiken we Python 3.7 en de libraries Tensorflow, Numpy, Sci-kit Image, and Matplotlib. Deze libraries zijn al in de environment die we net hebben aagemaakt ge√Ønstalleerd. Vervolgens gaan we de libraries importeren, dit doen  we met het commando 'import':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qhuV6JY8GBT"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "# Allow image embeding in notebook\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Imaging\n",
        "# import skimage.data\n",
        "import cv2\n",
        "import skimage.transform\n",
        "# ML models\n",
        "import tensorflow as tf\n",
        "# Various\n",
        "import zipfile\n",
        "print(\"inladen libraries is klaar!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1yVoMP-8GBU"
      },
      "source": [
        "## Training Dataset\n",
        "\n",
        "We gebruiken in dit project een verzameling verkeersborden uit [Belgie](http://btsd.ethz.ch/shareddata/). De beelden zijn opgedeeld in twee mappen:\n",
        "\n",
        "```\n",
        "/data/Training/\n",
        "/data/Testing/\n",
        "```\n",
        "Beide directories hebben 62 sub-directories (0000 tot 0061). De naam van de sub-directory representeert het type verkeersborden (het label). \n",
        "\n",
        "Als we de volgende twee cellen runnen, dan worden de afbeeldingen en labels (Training, Testing) gedownload onder de map datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2K5PrHZ8GBU"
      },
      "outputs": [],
      "source": [
        "!wget -nc https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Training.zip\n",
        "with zipfile.ZipFile(\"BelgiumTSC_Training.zip\") as zf:\n",
        "  zf.extractall(\"../data/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy3_fdip8GBU"
      },
      "outputs": [],
      "source": [
        "!wget -nc https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Testing.zip\n",
        "\n",
        "with zipfile.ZipFile(\"BelgiumTSC_Testing.zip\") as zf:\n",
        "  zf.extractall(\"../data/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and testing datasets.\n",
        "ROOT_PATH = \"./\"\n",
        "train_data_dir = os.path.join(ROOT_PATH, \"../data/Training\")\n",
        "test_data_dir = os.path.join(ROOT_PATH, \"../data/Testing\")"
      ],
      "metadata": {
        "id": "8TFFdIzC_cC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyxWFTzW8GBV"
      },
      "source": [
        "## De traindata inladen\n",
        "\n",
        "Vervolgens gaan we data die we net gedownload hebben, inladen in Python met een functie def load_data die we hier aanmaken."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "SwC29QIF8GBV"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir):\n",
        "    \"\"\"Loads a data set and returns two lists:\n",
        "    \n",
        "    images: a list of Numpy arrays, each representing an image.\n",
        "    labels: a list of numbers that represent the images labels.\n",
        "    \"\"\"\n",
        "    # Get all subdirectories of data_dir. Each represents a label.\n",
        "    directories = [d for d in os.listdir(data_dir) \n",
        "                   if os.path.isdir(os.path.join(data_dir, d))]\n",
        "    # Loop through the label directories and collect the data in\n",
        "    # two lists, labels and images.\n",
        "    labels = []\n",
        "    images = []\n",
        "    for d in directories:\n",
        "        label_dir = os.path.join(data_dir, d)\n",
        "        file_names = [os.path.join(label_dir, f) \n",
        "                      for f in os.listdir(label_dir) if f.endswith(\".ppm\")]\n",
        "        # For each label, load it's images and add them to the images list.\n",
        "        # And add the label number (i.e. directory name) to the labels list.\n",
        "        for f in file_names:\n",
        "            images.append(cv2.imread(f))\n",
        "            labels.append(int(d))\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "images, labels = load_data(train_data_dir)\n",
        "\n",
        "print(\"Data is ingeladen in Python!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn4reQnD8GBW"
      },
      "source": [
        "We hebben nu twee lijsten:\n",
        "\n",
        "* **images** een lijst van plaatjes in de vorm van een numpy array.\n",
        "* **labels** een lijst met labels in de vom van een array van getallen van 0 tot en met 61\n",
        "\n",
        "De lijsten staan met elkaar in verbinding doo de gehanteerde volgorde."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bspJCcJB8GBX"
      },
      "source": [
        "## De data verkennen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_ftg8jN8GBY"
      },
      "outputs": [],
      "source": [
        "print(\"Unique Labels: {0}\\nTotal Images: {1}\".format(len(set(labels)), len(images)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aGaFKrb8GBY"
      },
      "source": [
        "Hieronder maken we een tabel met van elk label het eerste voorbeeld."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ-Gl5K18GBY"
      },
      "outputs": [],
      "source": [
        "def display_images_and_labels(images, labels):\n",
        "    \"\"\"Display the first image of each label.\"\"\"\n",
        "    unique_labels = set(labels)\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    i = 1\n",
        "    for label in unique_labels:\n",
        "        # Pick the first image for each label.\n",
        "        image = images[labels.index(label)]\n",
        "        plt.subplot(8, 8, i)  # A grid of 8 rows x 8 columns\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Label {0} ({1})\".format(label, labels.count(label)))\n",
        "        i += 1\n",
        "        _ = plt.imshow(image[..., ::-1])\n",
        "    plt.show()\n",
        "\n",
        "display_images_and_labels(images, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHmV9Tsy8GBZ"
      },
      "source": [
        "Kijk eens! Dat ziet er goed uit! Zo te zien hebben we van alle verkeersborden een plaatje dat min of meer het hele beeld vult. Het valt wel op dat de plaatjes niet helemaal vierkant zijn, dat moeten we later wel oplossen. \n",
        "\n",
        "Laten we eerst nog eens een type wat meer in detail bekijken. Laten we eens beginnen met type 42."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAp9Due98GBZ"
      },
      "outputs": [],
      "source": [
        "def display_label_images(images, label):\n",
        "    \"\"\"Display images of a specific label.\"\"\"\n",
        "    limit = 24  # show a max of 24 images\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    i = 1\n",
        "\n",
        "    start = labels.index(label)\n",
        "    end = start + labels.count(label)\n",
        "    for image in images[start:end][:limit]:\n",
        "        plt.subplot(3, 8, i)  # 3 rows, 8 per row\n",
        "        plt.axis('off')\n",
        "        i += 1\n",
        "        plt.imshow(image[..., ::-1])\n",
        "    plt.show()\n",
        "\n",
        "display_label_images(images, 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21kaklKm8GBa"
      },
      "source": [
        "Ahah! Alle snelheidsgeboden vallen in dezelfde klasse. Tensorflow zou daar in principe mee om mee moeten kunnen gaan, maar het is wel goed om dit even gezien te hebben.\n",
        "\n",
        "Kan je nu zelf andere klasses bekijken? Probeer bijvoorbeeld eens 26 en 27 te bekijken. Wat zou dit straks kunnen betekenen?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHzbibhT8GBa"
      },
      "source": [
        "## Verschillende formaten\n",
        " \n",
        "Het is over het algemeen handig om de plaatjes in hetzelfde formaat te hebben. We hebben al gezien dat dat in dit geval niet zo is. Een goede manier om dit op te lossen is om de plaatjes handmatig bij te knippen zodat we geen belangrijke delen missen.\n",
        "\n",
        "Vandaag pakken we het snel aan, dus gaan we voor een hack: We schalen de plaatjes automatisch zonde te knippen. We gooien dus niks weg maar vervormen de beelden dus licht.\n",
        "\n",
        "Hoe groot zijn de plaatjes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJwRWBOE8GBa"
      },
      "outputs": [],
      "source": [
        "for image in images[:5]:\n",
        "    print(\"shape: {0}, min: {1}, max: {2}\".format(image.shape, image.min(), image.max()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SKmaKW-8GBb"
      },
      "source": [
        "Rond de 128 bij 128 dus. Als we ze nou eens allemaal afbeelden op 32x32, dan hebben we minder data (dus sneller resultaat) en ze zijn allemaal van hetzelfde formaat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "NGDDSQqZ8GBb"
      },
      "outputs": [],
      "source": [
        "# Resize images\n",
        "images32 = [skimage.transform.resize(image, (32, 32))\n",
        "                for image in images]\n",
        "display_images_and_labels(images32, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frRjCzJ48GBb"
      },
      "source": [
        "Minder scherp, maar nog steeds herkenbaar!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqP3q5BS8GBc"
      },
      "source": [
        "# Minimum Viable Model\n",
        "Nu bouwen we een simpel neuraal netwerk dat plaatjes voor ons gaat classificeren. Het bestaat uit twee input tensors (de plaatjes en de labels), een tussenlaagje dat de plaatjes plat maakt, gevolgd door een fully connected layer die de voorspelling maakt.\n",
        "\n",
        "Een fully connected layer verbindt alle inputs naar elk van zijn eigen nodes. Deze layer heeft er 62 (een voor elke klasse)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwVCytB-8GBc"
      },
      "outputs": [],
      "source": [
        "labels_a = np.array(labels)\n",
        "images_a = np.array(images32)\n",
        "print(\"labels: \", labels_a.shape, \"\\nimages: \", images_a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(62, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0tX9D6TrQw_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1wiKzS38GBc"
      },
      "source": [
        "## Training\n",
        "We gaan het model nu 100 keer trainen. (We gebruiken de ADAM optimizer om de cross-entropy zo laag mogelijk te krijgen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Optimizer\n",
        "    # Loss function to minimize\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ],
      "metadata": {
        "id": "Qa49Op5gSou_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fit model on training data\")\n",
        "history = model.fit(\n",
        "    images_a,\n",
        "    labels_a,\n",
        "    batch_size=64,\n",
        "    epochs=100,\n",
        "    # We pass some validation for\n",
        "    # monitoring validation loss and metrics\n",
        "    # at the end of each epoch\n",
        "    #validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "id": "dT6kg3OUTGSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"])"
      ],
      "metadata": {
        "id": "Of2_-ZT7Wu-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b6Ffpt48GBd"
      },
      "source": [
        "## Het model toepassen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7DV80yv8GBd"
      },
      "source": [
        "Laten we eens kijken welk percentage ons model nu goed heeft."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(np.argmax(model.predict(images_a), axis=1) == labels_a)"
      ],
      "metadata": {
        "id": "hLkmP6dDX3WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znXO7gHZ8GBd"
      },
      "source": [
        "Alright een percentage rond de 70% procent... klinkt goed!\n",
        "\n",
        "Hoe ziet dat er dan uit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcLfSo3p8GBd"
      },
      "outputs": [],
      "source": [
        "# Pick 10 random images\n",
        "sample_indexes = random.sample(range(len(images32)), 10)\n",
        "sample_images = np.array([images32[i] for i in sample_indexes])\n",
        "sample_labels = [labels[i] for i in sample_indexes]\n",
        "\n",
        "# Run the \"predicted_labels\" op.\n",
        "predicted = np.argmax(model.predict(sample_images),axis=1)\n",
        "\n",
        "# Display the predictions and the ground truth visually.\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(len(sample_images)):\n",
        "\n",
        "    truth = sample_labels[i]\n",
        "    prediction = predicted[i]\n",
        "    plt.subplot(5, 2,1+i)\n",
        "    plt.axis('off')\n",
        "    color='green' if truth == prediction else 'red'\n",
        "    plt.text(40, 10, \"Truth:        {0}\\nPrediction: {1}\".format(truth, prediction), \n",
        "             fontsize=12, color=color)\n",
        "    plt.imshow(sample_images[i][..., ::-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdCfQOMl8GBe"
      },
      "source": [
        "## Evaluatie\n",
        "\n",
        "Het is aardig dat we nu goed scoren op de trainset, maar goed dit model nu ook echt iets geleerd?\n",
        "\n",
        "Daar hebben we de testset voor, weet je nog?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tJwj6jP8GBe"
      },
      "outputs": [],
      "source": [
        "# Load the test dataset.\n",
        "test_images, test_labels = load_data(test_data_dir)\n",
        "\n",
        "print(\"de testset is ingeladen!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkVBd8Vm8GBe"
      },
      "outputs": [],
      "source": [
        "# Transform the images, just like we did with the training set.\n",
        "test_images32 = [skimage.transform.resize(image, (32, 32))\n",
        "                 for image in test_images]\n",
        "display_images_and_labels(test_images32, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run predictions against the full test set.\n",
        "predicted = np.argmax(model.predict(np.array(test_images32)), axis=1)\n",
        "# Calculate how many matches we got.\n",
        "accuracy = np.mean(predicted == test_labels)\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy))"
      ],
      "metadata": {
        "id": "Mv3dq22McPxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Probeer je eigen model te maken/aanpassen**\n",
        "\n",
        "https://keras.io/api/layers/"
      ],
      "metadata": {
        "id": "4EVAS2bKMQ-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(inputs)\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(62, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Optimizer\n",
        "    # Loss function to minimize\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "S6kiLKrtMHji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fit model on training data\")\n",
        "history = model.fit(\n",
        "    images_a,\n",
        "    labels_a,\n",
        "    batch_size=64,\n",
        "    epochs=100,\n",
        "    # We pass some validation for\n",
        "    # monitoring validation loss and metrics\n",
        "    # at the end of each epoch\n",
        "    validation_data=(np.array(test_images32), np.array(test_labels)),\n",
        ")"
      ],
      "metadata": {
        "id": "hnwk8dVnPItU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}